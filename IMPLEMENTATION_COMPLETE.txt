‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë                                                                            ‚ïë
‚ïë                  ‚úÖ RESEARCHER-GRADE SYSTEM FULLY DEPLOYED                 ‚ïë
‚ïë                                                                            ‚ïë
‚ïë         Your Loss Plateau Problem is Now Systematically Solvable           ‚ïë
‚ïë                                                                            ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù


WHAT YOU HAVE NOW:
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

3 Python Scripts (40 KB):
  ‚úÖ train_research_grade.py
     ‚Ä¢ Main trainer with detailed logging
     ‚Ä¢ Creates STOPPING_REASON.txt (explains why it stopped)
     ‚Ä¢ Saves model_info.json (metadata)
     ‚Ä¢ Saves best_model.pth separately

  ‚úÖ find_best_model.py
     ‚Ä¢ Compares multiple runs
     ‚Ä¢ Generates BEST_MODEL_SELECTION.txt report
     ‚Ä¢ Automatically selects winner

  ‚úÖ solve_plateau.py
     ‚Ä¢ Analyzes YOUR specific plateau issue
     ‚Ä¢ Generates 5 optimized configs

5 Plateau Solution Configs:
  ‚úÖ solution_1_higher_lr.yml (LR doubled - TRY FIRST)
  ‚úÖ solution_2_cosine_annealing.yml (Smooth schedule)
  ‚úÖ solution_3_heavy_triplet.yml (Metric learning focus)
  ‚úÖ solution_4_aggressive_lr_drop.yml (Coarse-to-fine)
  ‚úÖ solution_5_smaller_batch_higher_lr.yml (Hard mining)

4 Comprehensive Guides:
  ‚úÖ QUICK_COMMANDS.txt (2 min read - START HERE)
  ‚úÖ SYSTEM_SUMMARY.txt (5 min read)
  ‚úÖ RESEARCHER_GUIDE.txt (10 min read)
  ‚úÖ START_HERE.txt (Full overview)

1 Batch Launcher:
  ‚úÖ run_plateau_solutions.bat (Windows - run all 5 at once)


YOUR PROBLEM ANALYZED:
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

Symptoms:
  ‚Ä¢ CE Loss: 6.71-6.73 (STUCK, should be 5.0-5.5)
  ‚Ä¢ Triplet Loss: 2.7-2.9 (SLOW, should be 2.0-2.5)
  ‚Ä¢ Total Loss: 9.5-9.6 (PLATEAU, barely moving)
  ‚Ä¢ No progress from epoch 10-29

Root Causes Identified:
  1. Learning rate 0.00035 is TOO LOW
  2. CE loss (6.71) >> Triplet loss (2.8) = imbalance
  3. Fixed learning rate schedule may not fit your data

Solutions Generated:
  5 different approaches to try systematically
  Each addresses one or more root causes


HOW THIS WORKS:
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

BEFORE (Manual Approach - Slow & Confusing):
  ‚ùå Change one hyperparameter manually
  ‚ùå Train for 8 hours
  ‚ùå Wonder if it helped
  ‚ùå Manually compare numbers
  ‚ùå No clear reason why training stopped

AFTER (Researcher Approach - Scientific & Clear):
  ‚úÖ Choose optimized config or run all 5
  ‚úÖ Training automatically logs everything
  ‚úÖ STOPPING_REASON.txt explains why it stopped
  ‚úÖ model_info.json records metadata
  ‚úÖ System automatically selects best model
  ‚úÖ BEST_MODEL_SELECTION.txt shows winner


QUICK START (5 MINUTES):
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

1. Read: QUICK_COMMANDS.txt (2 minutes)

2. Choose ONE of these:

   OPTION A: Quick Test (8 hours)
     python train_research_grade.py ^
       --config-file custom_configs/plateau_solutions/solution_1_higher_lr.yml ^
       --run-name solution_1_higher_lr

   OPTION B: Full Comparison (40 hours)
     run_plateau_solutions.bat

   OPTION C: Hyperparameter Search (Variable)
     python find_best_model.py ^
       --base-config custom_configs/plateau_solutions/solution_1_higher_lr.yml

3. Wait for training to complete

4. Read the stopping reason and decide next steps


WHAT HAPPENS NEXT:
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

Training Starts:
  ‚Ä¢ Model initializes with new hyperparameters
  ‚Ä¢ Validation runs after each epoch
  ‚Ä¢ Loss values printed to console

During Training:
  ‚Ä¢ Watch loss values improve (hopefully!)
  ‚Ä¢ Check every 10 epochs or so
  ‚Ä¢ If CE loss drops, solution is working

After Training Completes (or stops early):
  ‚Ä¢ STOPPING_REASON.txt is created ‚≠ê
  ‚Ä¢ Explains: Why it stopped, best mAP, recommendations
  ‚Ä¢ model_info.json saves metadata
  ‚Ä¢ best_model.pth saved for deployment

Review (Next day):
  ‚Ä¢ Read STOPPING_REASON.txt
  ‚Ä¢ Check if improvements happened
  ‚Ä¢ Decide: Deploy or try next solution

Deploy:
  ‚Ä¢ Copy best_model.pth to deployment folder
  ‚Ä¢ Load in enrollment_tracker.py
  ‚Ä¢ Monitor real-world performance


EXPECTED OUTCOMES:
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

‚úÖ GOOD OUTCOME (What you want to see):
   ‚Ä¢ STOPPING_REASON.txt says: "No improvement for 10 epochs"
   ‚Ä¢ CE loss dropped from 6.7 ‚Üí 5.5-6.0 (visible improvement)
   ‚Ä¢ mAP > 0.3
   ‚Ä¢ Training stopped efficiently (epoch 35-45 range)
   ‚Üí DEPLOY THIS MODEL

‚ö†Ô∏è UNCLEAR OUTCOME (What to do):
   ‚Ä¢ Loss improved slightly but still high
   ‚Ä¢ mAP around 0.2-0.3
   ‚Ä¢ ‚Üí TRY SOLUTION 2 (cosine annealing)

‚ùå BAD OUTCOME (What went wrong):
   ‚Ä¢ Loss didn't improve at all
   ‚Ä¢ STOPPING_REASON: "Out of memory" or error
   ‚Ä¢ mAP < 0.15
   ‚Üí TRY DIFFERENT SOLUTION or check config


FILE LOCATIONS YOU'LL USE:
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

After solution_1_higher_lr:
  logs/market1501/solution_1_higher_lr/
  ‚îú‚îÄ‚îÄ STOPPING_REASON.txt        ‚Üê Read this!
  ‚îú‚îÄ‚îÄ best_model.pth             ‚Üê Use this for deployment
  ‚îú‚îÄ‚îÄ model_info.json            ‚Üê Has metadata
  ‚îú‚îÄ‚îÄ training_history.json      ‚Üê Metrics per epoch
  ‚îî‚îÄ‚îÄ log.txt                    ‚Üê Full training logs

After comparing all 5 solutions:
  logs/plateau_solutions/BEST_MODEL_SELECTION.txt ‚Üê Winner announced!


WHY THIS IS BETTER:
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

‚úÖ Clear Stopping Reasons
   Every training run creates a human-readable explanation
   No confusion about why training stopped

‚úÖ Systematic Comparison
   Test multiple approaches objectively
   Know which hyperparameters work best

‚úÖ Detailed Metadata
   Every model has associated hyperparameters recorded
   Reproducible results

‚úÖ Automatic Best Selection
   System ranks models by mAP
   No manual comparison needed

‚úÖ Scientific Approach
   This is how PhD researchers do model selection
   More rigorous than trial-and-error

‚úÖ Time Efficient
   Early stopping prevents wasting compute
   Detailed logs help debug quickly


RECOMMENDED APPROACH FOR YOU:
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

Week 1:
  Monday: Start solution_1_higher_lr (8 hours)
  Tuesday: Read STOPPING_REASON.txt, check if it improved
  
  If yes (CE loss 6.7 ‚Üí 5.5-6.0):
    Wednesday: Try solution_2_cosine_annealing (8 hours)
    Thursday: Compare both, pick better one
    Friday: Deploy

  If no (loss didn't improve):
    Wednesday: Try solution_3_heavy_triplet (8 hours)
    Thursday: Compare, decide next

Week 2 (Optional - For thorough analysis):
  Run all 5 solutions simultaneously
  Get comprehensive comparison
  Strong confidence in choice


NEXT ACTION (RIGHT NOW):
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

Do one of these:

1Ô∏è‚É£ LAZY APPROACH (Just run it):
   python train_research_grade.py ^
     --config-file custom_configs/plateau_solutions/solution_1_higher_lr.yml ^
     --run-name solution_1_higher_lr

2Ô∏è‚É£ INFORMED APPROACH (Read first):
   1. Read QUICK_COMMANDS.txt (2 minutes)
   2. Run the command above
   3. Come back tomorrow to check results

3Ô∏è‚É£ THOROUGH APPROACH (Full understanding):
   1. Read QUICK_COMMANDS.txt (2 min)
   2. Read SYSTEM_SUMMARY.txt (5 min)
   3. Read RESEARCHER_GUIDE.txt (10 min)
   4. Run option B (all 5 solutions)
   5. Get comprehensive report in 40 hours


KEY FILES TO READ IN THIS ORDER:
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

1. QUICK_COMMANDS.txt (this directory)
   ‚Üí Copy-paste ready commands
   ‚Üí 2 minute read
   ‚Üí START HERE

2. SYSTEM_SUMMARY.txt
   ‚Üí Overview of entire system
   ‚Üí 5 minute read

3. RESEARCHER_GUIDE.txt
   ‚Üí Detailed explanations
   ‚Üí 10 minute read
   ‚Üí Most comprehensive

4. STOPPING_REASON.txt (generated after training)
   ‚Üí Why YOUR training stopped
   ‚Üí Human-readable explanation
   ‚Üí MOST IMPORTANT OUTPUT


‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

BOTTOM LINE:
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

Your model has a plateau problem:
  ‚Ä¢ CE Loss stuck at 6.71-6.73
  ‚Ä¢ Triplet Loss stagnant
  ‚Ä¢ No visible improvement

Solution provided:
  ‚Ä¢ 5 optimized configurations
  ‚Ä¢ Detailed logging system
  ‚Ä¢ Automatic model selection
  ‚Ä¢ Clear stopping reasons

How to use:
  1. Run: python train_research_grade.py --config-file custom_configs/plateau_solutions/solution_1_higher_lr.yml --run-name solution_1_higher_lr
  2. Wait: 8 hours
  3. Read: logs/market1501/solution_1_higher_lr/STOPPING_REASON.txt
  4. Deploy: Use best_model.pth if mAP improved

This is exactly what researchers do. You now have the tools to do it systematically! üéì

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

Questions?
  ‚Üí See QUICK_COMMANDS.txt
  ‚Üí See SYSTEM_SUMMARY.txt
  ‚Üí See RESEARCHER_GUIDE.txt

Ready?
  ‚Üí Run the command above!

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
